@book{CVNN_book,
  author = {Akira Hirose},
  title = {Complex-Vaued Neural Networks, 2nd Edition},
  year = 2012,
}

@misc{ko2022coshnet,
      title={CoShNet: A Hybrid Complex Valued Neural Network using Shearlets},
      author={Manny Ko and Ujjawal K. Panchal and Héctor Andrade-Loarca and Andres Mendez-Vazquez},
      year={2022},
      eprint={2208.06882},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{biocvnn,
author="Yu, Ryan
and Wood, Andrew
and Cohen, Sarel
and Hershcovitch, Moshick
and Waddington, Daniel
and Chin, Peter",
editor="Maglogiannis, Ilias
and Iliadis, Lazaros
and Macintyre, John
and Cortez, Paulo",
title="Biologically Plausible Complex-Valued Neural Networks and Model Optimization",
booktitle="Artificial Intelligence Applications and Innovations",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="369--382",
abstract="Artificial Neural Networks (ANNs) are thinly based on biological neural pathways. In an ANN, each node computes its activation by applying a non-linearity to a weighted sum of its inputs. While this formulation has been wildly successful for a variety of tasks, it is still a far cry from its biological counterpart, largely due to ANNs lack of phase information during computation. In this paper, we adapt ANNs to operate on complex values which naturally allows the inclusion of phase information during the forward pass. We demonstrate that our complex-valued architecture generally performs better compared to real-valued and other complex-valued networks in similar conditions. Additionally, we couple our model with a biologically inspired form of dimensionality reduction and present our findings on the MNIST and MusicNet data sets.",
isbn="978-3-031-08333-4"
}
@misc{hintonforwardforward,
      title={The Forward-Forward Algorithm: Some Preliminary Investigations},
      author={Geoffrey Hinton},
      year={2022},
      eprint={2212.13345},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{phasecongruencehuman,
author = {Morrone, M and Burr, David},
year = {1989},
month = {01},
pages = {221-45},
title = {Feature Detection in Human Vision: A Phase-Dependent Energy Model},
volume = {235},
journal = {Proceedings of the Royal Society of London. Series B, Containing papers of a Biological character. Royal Society (Great Britain)},
doi = {10.1098/rspb.1988.0073}
}

@article{fashionmnist,
  author    = {Han Xiao and
               Kashif Rasul and
               Roland Vollgraf},
  title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning
               Algorithms},
  journal   = {CoRR},
  volume    = {abs/1708.07747},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.07747},
  archivePrefix = {arXiv},
  eprint    = {1708.07747},
  timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{yang2021complex,
      title={Complex Transformer: A Framework for Modeling Complex-Valued Sequence},
      author={Muqiao Yang and Martin Q. Ma and Dongyu Li and Yao-Hung Hubert Tsai and Ruslan Salakhutdinov},
      year={2021},
      eprint={1910.10202},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{mazumder2021multilingual,
  title={Multilingual Spoken Words Corpus},
  author={Mazumder, Mark and Chitlangia, Sharad and Banbury, Colby and Kang, Yiping and Ciro, Juan Manuel and Achorn, Keith and Galvez, Daniel and Sabini, Mark and Mattson, Peter and Kanter, David and others},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@misc{arjovsky2016unitary,
      title={Unitary Evolution Recurrent Neural Networks},
      author={Martin Arjovsky and Amar Shah and Yoshua Bengio},
      year={2016},
      eprint={1511.06464},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{TESS,
author = {Pichora-Fuller, M. Kathleen and Dupuis, Kate},
publisher = {Borealis},
title = {{Toronto emotional speech set (TESS)}},
year = {2020},
version = {DRAFT VERSION},
doi = {10.5683/SP2/E8H2MF},
url = {https://doi.org/10.5683/SP2/E8H2MF}
}
